%%%%%%%%%%%%%%%%%%%%% chapter.tex %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% sample chapter
%
% Use this file as a template for your own input.
%
%%%%%%%%%%%%%%%%%%%%%%%% Springer-Verlag %%%%%%%%%%%%%%%%%%%%%%%%%%
%\motto{Use the template \emph{chapter.tex} to style the various elements of your chapter content.}
\chapter{Literature Review 2}
\label{lit_review_2} % Always give a unique label
% use \chaptermark{}
% to alter or adjust the chapter heading in the running head

\abstract*{Each chapter should be preceded by an abstract (10--15 lines long) that summarizes the content. The abstract will appear \textit{online} at \url{www.SpringerLink.com} and be available with unrestricted access. This allows unregistered users to read the abstract as a teaser for the complete chapter. As a general rule the abstracts will not appear in the printed version of your book unless it is the style of your particular book or that of the series to which your book belongs.
Please use the 'starred' version of the new Springer \texttt{abstract} command for typesetting the text of the online abstracts (cf. source file of this chapter template \texttt{abstract}) and include them with the source files of your manuscript. Use the plain \texttt{abstract} command if the abstract is also to appear in the printed version of the book.}

\abstract{Each chapter should be preceded by an abstract (10--15 lines long) that summarizes the content. The abstract will appear \textit{online} at \url{www.SpringerLink.com} and be available with unrestricted access. This allows unregistered users to read the abstract as a teaser for the complete chapter. As a general rule the abstracts will not appear in the printed version of your book unless it is the style of your particular book or that of the series to which your book belongs.\newline\indent
Please use the 'starred' version of the new Springer \texttt{abstract} command for typesetting the text of the online abstracts (cf. source file of this chapter template \texttt{abstract}) and include them with the source files of your manuscript. Use the plain \texttt{abstract} command if the abstract is also to appear in the printed version of the book.}

\section{Localizing Location Using Mobile Phone Sensors}
\label{lit_rev:10}

In order to generate a precious map of image spheres with accurate relative location data we should have a mechanism to capture precious location information while capturing image spheres. For location capturing purpose the trivial technology is using Global Positioning System (GPS) to capture the location. GPS current accuracy is around 5m, which is not that suitable for our usage where we need a higher accuracy of location capturing. Since our system?s requirement is capturing relative location of image spheres, we thought of using accelerometer and gyroscope of a mobile phone to get those necessary location information.

\subsection{Precise Indoor Localization Using Smartphones}
Martin et al. introduce an indoor localization application \cite{48} using sensors of a smartphone as research paper in international conference on multimedia 2010. Their system is using Wi-Fi unit, cellular communication unit, accelerometer and magnetometer of a smartphone to capture location information.

\subsubsection{Approach}
According to authors GPS is only reliable outdoor localizing where device is directly visible to satellite, also accelerometer along gives noisy readings. As they expect initially Wi-Fi unit of the mobile device is the most reliable approach to localize their experimental unit. Authors use Received Signal Strength Indication (RSSI) information of Wi-Fi beacon packets within buildings to generate a radio map of different locations. They have been faced some issues when using different devices to capture location data which they refer as ``signal reception bias" which caused by characteristics of different antennas of different devices. Authors have used accelerometer readings and magnetometer reading to identify the orientation of the device which they have used to improve the accuracy of location information.

\subsubsection{Experiment}Authors has deployed their experiment in a building where it has infrastructure of Wi-Fi access points that give fully coverage to the building. They have used android base mobile devices to measure Wi-Fi strength of the locations. To keep the consistency of the RSSI information, Wi-Fi beacons that have higher than -80 dBm are filtered for experiment. In averagely around 25 Wi-Fi radios there were listened and approximately 40\% of them were with RSSI above -80 dBm.In the experimental setup they have used, each Wi-Fi access point has contained 5 different radios. Averaging RSSI values over same access point has resulted more stable output. They introduce this approach as ?Nearest Neighbour in signal space and Access Point average?
\subsubsection{Conclusion}As a conclusion for this approach by Martin et al. the approach delivers up to 1.5 meters accuracy level without using extra hardware. But when this approach compare with our requirement of capturing location information, this approach seems impractical for some of our use cases where there does not exist fixed Wi-Fi infrastructure.

\subsection{Concept for Building a Smartphone Based Indoor Localization System}
Willemsen et al. propose a concept for indoor localization based on smartphone with a research paper published in International Conference on Information Fusion, 2014 \cite{49}. Proposed system uses Micro Electro Mechanical System (MEMS) sensors embedded in smartphones. Accelerometer, gyroscope, magnetic field sensor, barometer are those MEMS sensors that enable localization where there is no reliable GPS support. Fig. \ref{fig2_workflow} gives an overview of the system that proposed by Willemsen et al.

\begin{figure}[htbp]
\begin{center}
\includegraphics[]{Figures/31.png}
\caption{Suggested Workflow}
\label{fig2_workflow}
\end{center}
\end{figure}

This research contains several steps that includes hardware selection, evaluation of hardware, position estimation, routing and implementation. Position estimation part of their research is the most relevant part for our application.

\subsubsection{Usage of Sensors}

\paragraph{\textbf{Barometer}}
Authors have used a barometer to measure air pressure and calculated relative heights from sea level. If barometer reading is pi height related to that pressure hi is given by,

\begin{align}
\label{eqn:eq101}
\begin{split}

\[
h_i=\left(1-\sqrt[5.255]{\frac{p_i}{1013.25}}\right)*\frac{288.15}{0.0065}
\]

\end{split}
\end{align}
With the help of barometer readings, authors could able to distinguish each floor of the test building. Height calculated using barometer readings were accurate up to 1m, floor was distinguished only using the mean value of barometer readings.

\paragraph{\textbf{Accelerometer}}
3-axis accelerometer integrated with a smartphone is used to level the smartphone coordination system while navigating. Even double integration of accelerometer outputs distance travelled, but the strong drift of the embedded accelerometer has provided unusable results. Therefor authors had to use accelerometer as a pedometer. They had calibrated the accelerometer with a method favouring Kalman filter.

\paragraph{\textbf{Fusion Kalman Filter}}
Position estimation of gyroscope and accelerometer data is not sufficient enough to calculate accurate position details. Authors have used Kalman filter to combine support information and MEMS readings. Before use in Kalman filter sensor data were averaged in order to reduce noise component generated by sensors. Height information that calculated with barometer readings is fed to Kalman filter. Fig. \ref{fig2_kalman_filter} shows the effect of Kalman filter. Blue line is related to location calculation without filter and red coloured line indicates location details captured with Kalman filter.

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=\textwidth]{Figures/32.png}
\caption{Trajectory Kalman Filter}
\label{fig2_kalman_filter}
\end{center}
\end{figure}

\subsubsection{Supportive Additives for Better Accuracy}
Authors also tried RSSI information of Wi-Fi beacons to improve the accuracy of location capturing. The approach of using RSSI information is almost similar to approach in previous section.

\section{Scene Description Languages}

\subsection{XML Based Scene Description Language for a Virtual Museum}
In their work \cite{50} the authors discuss the Scene Description Language (SDL) they have used specifically for a 3D Virtual Museum, to be viewed through the desktop.Three characteristics of a virtual reality system has been identified by John Vince \cite{51}. These are, immersion, interaction and imagination. The authors have not considered the immersive aspect of virtual reality as the use case is to be viewed on a desktop when creating the SDL.

\subsubsection{Related Work}
Under related work, the authors have mentioned image-based rendering, which they consider not to be of use for their use case, giving five different reasons. But, this is a closer approach to the approaches used in our research work. This is called Image Based Rendering (IBR) technology \cite{52}.
Another approach which they mention as being used in museums is Projection Based Immersive Virtual Environments, which are far from our approach towards virtual reality.
The paper mentions another approach, which uses Virtual Reality Modelling Language (VRML) \cite{53} or the improved version eXtensible 3D (X3D) by the Web3D Consortium \cite{54}. These are defined as standard document formats to describe 3D objects in virtual environments X3D is using XML code and this enables it to be smoothly adapted to other applications, especially web applications. Since the design of X3D is guided by component technology, it is easily extendable.
The above services are well suited for web environments.

\subsubsection{About the XVM Backend}
The authors suggest a schema called XML-Based Scene Description Language for 3D Virtual Museum (XVM) for their use case of virtual museum \cite{50}. They have designed this with four design issues applicable to the virtual museum, out of which two are applicable to our system. Firstly, the displayed content is repeated, and indexed. Secondly, it requires an authoring mechanism to construct and to parse the scenes.

\begin{figure}[htbp]
\begin{center}
\includegraphics[]{Figures/33.png}
\caption{System Structure of the Virtual Museum}
\label{fig2_virtual_museum}
\end{center}
\end{figure}

As shown in Fig. \ref{fig2_virtual_museum}, the XVM works separately, but parallel to the web server. This helps to maintain the real-time rendering in the XVM viewer by separation of the display environment from the rest.The XML mark-up has been used for SVM for the following reasons, according to the authors:
\begin{enumerate}\item{Interoperability}\item{Self-Description}\item{Scalability}\item{Simplicity}\item{Flexibility}
\end{enumerate}

\subsubsection{Scene Description Language}The Scene Description Language follows an Organizational Structure (i.e. a Concept Hierarchy), with dummy nodes representing a cluster of objects. There are special Node types for concrete objects, (such as Walls, Floor, and Ceiling) and these can carry attributes as well (E.g.: for texture). The scheme also contains a mechanism to add dynamic content by enabling the inclusion of dummy nodes within other nodes.
Another special feature of the schema is that it has a mechanism to allow reused items to be defined once, and used multiple times, allowing faster loading.
\subsubsection{Future Work}Future work, in their research are ordering the download of models according to the origin and direction. This is also important in our work as it plays an important role in optimizing the loading process.
Also, the interoperability with other SDLs should be taken into note when creating the scheme, as being able to convert between such formats automatically is of considerable importance.
\subsubsection{Conclusion}The work referred to in the paper is quite similar to our work, but has some differences, especially considering their navigable environment being a computer generated 3D one. But the considerations which they have taken in while designing the XVM schema can be applied either directly or indirectly to our work, when designing our SDL.

\subsection{A Semantic Scene Description Language for Procedural Layout Solving}
The paper by Tutenel et al. \cite{55} describes a Scene Description Language for creating 3D models of an user-defined environment. Their approach is to automatically create sensible content for virtual worlds. The research work has been performed with special consideration towards designers, allowing them to specify which objects need to be present in a scene, their attributes and possible interrelationships.
Although the output of their research work is vastly different to our work and methodologies, the high-level ideas and other considerations of their work is valuable when creating our own SDL for navigable VR environments.
Some of the problems, which are solved by their research work are as follows:

\begin{itemize}
\item{SDLs including obscure parameterizations making the unintuitive.}\item{Being limited to mere geometrical representations.}\item{Having minimal semantic decision making abilities.}\item{Not being easy for use by designers.}\item{Inability to support multi-level / multi-type objects.}\end{itemize}
Apart from the latter two points, the other considerations can be applied up to various degrees in the design of our own SDL. As our research work does not include designing of the environment nor are complex object hierarchies, those points futile in our context.\subsubsection{Related Work}The authors refer to their own work \cite{56} where the importance of Semantics has been discussed in simulations and game environments. Another approach has been ontology languages for semantics in web document. They are also suitable to represent the semantics in the VR environments according to the authors. Some such examples are RDF \cite{57} and OWL \cite{58}. Also previous work by Aylett and Luck \cite{59} in combining AI to VR worlds has been taken as exemplary work when designing the work. Smart-objects in a VR environment as introduced in the work by Kallmann and Thalmann \cite{60} are objects which can interact with the users in the immersive world.
The authors proceed to cite previous work in the area of natural language processing and VR environments, which is important to their work because of the involvement of designers, who need to work intuitively and free of strict grammars. These are not in particular interest to our work, as the SDL annotations would be automatically generated.\subsubsection{Semantic Scene Description Language}The proposed language in their work, as proposed by the authors is to create a visual language that allows a designer to define the different elements of which scenes of a particular type consist.
Three major goals have been identified in designing the language:
\begin{itemize}\item{Describing which objects or components can or should be present in a given scene class.}\item{Describing the relationships between the available objects.}\item{Discerning variations depending on time and context.}
\end{itemize}
The main building block to achieve the goals above consists of description entities, (defining which objects need to be present and how they should be placed). Although the descriptions in this work consist of subjective descriptions and Natural Language Processing is needed at a latter stage, this concern does not apply to our work. But, corresponding descriptions are needed for navigation cues in the VR environment to be constructed in our work.
Also, the concept of area constraint, which forms another major part of the semantic language is interesting. This gives a spatial description, which is necessary considering the nature of our work, which requires navigation in a 3-dimensional space.
Next, a high-level definitions and a notion of context is introduced into the SDL. The high-level definition contains information general to the whole environment. Although not in the exact sense, a similar approach can be taken to describe the characteristics common to an area of navigation. The notion of context, too maybe needed, for example to distinguish the traversing along a flat land, or a steep pathway. The work of Tutenel et al. mentions a mechanism to identify the context, but is of a highly specific nature to their own work.\subsubsection{Conclusion}This work includes many insights into designing an SDL to be used in a Virtual Reality Environment. Especially the practical concerns and the various design decisions stated in the paper will be useful when generating our own Scene Description Language. Although each SDL is unique in its own and most of the features cannot be applied to another scenario, the high-level ideas are what we need to take example of, into our own work.

\section{Gesture Input for Smartphones}Gesture Recognition forms a key part of the intuitive navigation framework suggested by our research. In order to identify the best way of approaching this problem using machine learning, the solutions proposed by researchers to several related problems were explored \cite{61} \cite{62} \cite{63} \cite{64}.\subsection{Activity Recognition from Accelerometer Data}``Activity Recognition from Accelerometer Data" by Ravi et al. explores the possibility of recognizing user activity using accelerometer data \cite{64}.
In this research, a tri-axial accelerometer is used to measure acceleration along the x, y and z axes from which velocity and displacement is also estimated. Using this data, the authors propose a method of classifying users into several categories based on the activities they are performing. A set of eight activities in total are classified:

\begin{itemize}\item{Standing} \item{Walking}\item{Running}\item{Climbing up stairs}\item{Climbing down stairs}\item{Sit-ups}\item{Vacuuming}\item{Brushing teeth}
\end{itemize}
\subsubsection{Data Collection}The dataset used has been generated using two subjects, and labelling was done in a time-based manner, where each user was timed using a stopwatch. Data was labelled using a script which took the start and end times of each activity as input.\subsubsection{Feature Extraction}Feature extraction has been performed on the raw accelerometer data using a window of size 256 with an overlap of 128. This decision has been made based on a previous work \cite{}. A frequency of 50Hz has been used, which allows for a window of 5.12 seconds, which the authors have listed as sufficient to capture the key distinguishing characteristics of the different activities such as walking, running, etc. 
Four features have been extracted for each axes, namely:

\begin{itemize}\item{Mean}\item{Standard Deviation}\item{Energy (Using FFT)}\item{Correlation}
\end{itemize}
It is worth noting that the authors have captured the periodicity in the data by considering the frequency domain. To capture data periodicity, the energy feature has been calculated.  Correlation has been useful in differentiating among activities that involve translation in just a single dimension (walking is 1-dimensional whereas stair climbing is inherently 2-dimensional).\subsubsection{Results}The authors have tested data using several different settings.
\begin{enumerate}\item{Data collected for a single subject over different days, mixed together and cross-validated.}\item{Data collected for multiple subjects over different days, mixed together and cross-validated.}\item{Data collected for a single subject on one day used as training data, and data collected for the same subject on another day used as testing data.}\item{Data collected for a subject for one day used as training data, and data collected on another subject on another day used as testing data.}
\end{enumerate}

The authors have tested a number of different algorithms, among which Plurality Voting has given best results for the first 3 scenarios (99.57\%, 99.82\%, 90.61\% respectively), while for scenario 4, Boosted SVMs have given the best results (73.33\% Accuracy).
\subsection{Activity Recognition Using Cell Phone Accelerometers}
``Activity Recognition using Cell Phone Accelerometers" by Kwapisz et al. proposes a framework for classifying user activity into six separate classes using accelerometer data \cite{61}. In this research, the primary difference from most prior work is the use of a commercial mass-marketed device rather than a research-only device. A set of six activities in total are classified:
\begin{itemize} \item{Walking}\item{Jogging}\item{Climbing up stairs}\item{Climbing down stairs}\item{Sitting}\item{Standing}
\end{itemize}\subsubsection{Data Collection}The dataset used has been generated using two subjects, and labelling was done in a time-based manner, where each user was timed using a stopwatch. Data was labelled using a script which took the start and end times of each activity as input.
The authors have used a total of 29 volunteers in generating a dataset using Android smartphones. The volunteers have carried around the smartphone in the front leg pocket of their pants while performing the set of activities listed above. 
The data collection has been controlled by an application running on the phone which allowed, through a simple graphical user interface, the recording of user?s name, label and start and stop times of the activities being performed. Accelerometer data was collected every 50ms (20Hz). \subsubsection{Feature Extraction}In this work, features have been extracted from 10-second segments (200 readings per segment). The choice of segment width has been determined by the authors on the basis of it providing sufficient time to capture several cycles of repetitive motion. A comparison between 10-second and 20-second windows has yielded slightly better results for 10-second windows.In total, 43 features have been computed including:
\begin{itemize}\item{Average (3): Average acceleration (for each axis).}\item{Standard Deviation (3): Standard deviation (for each axis).}\item{Average Absolute Difference (3): Average absolute difference between the value of each of the 200 readings within the window and the mean value over those 200 values (for each axis).}\item{Average Resultant Acceleration (1): Average of the square roots of the sum of the values of each axis squared $\sqrt{x_i^2+y_i^2+z_i^2}$ over the window.}\item{Time Between Peaks (3): Time in milliseconds between peaks in the sinusoidal waves associated with most activities (for each axis).}\item{Binned Distribution (30): The authors determine the range of values for each axis (maximum$-$minimum), divide this range into 10 equal sized bins, and then record what fraction of the 200 values fell within each of the bins.}\end{itemize}
\subsubsection{Results}The authors have used three classification algorithms:
\begin{itemize}\item{Decision Trees (J48)}\item{Logistic Regression}\item{Multilayer Neural Networks}
\end{itemize}
Ten-fold cross validation has been used in each of the tests performed. The multilayer perceptron has classified samples with the highest overall accuracy (91.7\%).\subsection{Conclusion}The research presented in these papers is somewhat similar to the gesture recognition problem being explored by us, however there are significant differences in the problem tackled (Activity detection vs. Gesture Recognition) and the data collection (Accelerometer and Gyrosensor vs Accelerometer only) between the approaches. The feature extraction process detailed in this work can be extended to some extent in our work. In addition, the relatively high accuracy obtained by the methods indicate the possibility of obtaining accuracies which would provide sufficient precision for use in a real world system.

\section{Performance Enhancements}
Due to image panoramas being relatively large in size (due to being stitched from a number of normal images), image sequences are bound to use up considerable memory and bandwidth while in use in the visualization framework. Various researches have been explored to provide insights into minimizing this issue. 
\subsection{Compression based on Spatial Hierarchy}``A Spatial Image Hierarchy for Compression In Image-based-rendering" by Aliaga and Carlbom delves into the topic of generating a binary tree which stores original, reference and residual images. Images are extracted via a sequence of image warping operations from the tree \cite{45}.
\subsubsection{Tree Construction}The binary tree which indexes images is built in a bottom up manner, exploiting the coherence between images and within the same image. Images are added to the tree in 3 primary operations:

\begin{enumerate}\item{A node (with no children) is created for each image. }\item{The centers-of-projection (COP) of the images are connected using Delaunay triangulation. }\item{Edges in the triangulation are collapsed in edge priority order. (Euclidean distance between images is used as the metric for determining edge priority).}
\end{enumerate}
The tree consists primarily of three types of tree nodes: I-node, P-node, and N-node. New parent nodes (I-nodes) are placed at the same spatial location as one of their children and contain images formerly stored with that child. The child node at that location (N-node) simply becomes a reference to the parent. The other child node (P-node) becomes a residual image, the difference between the original child and the I-node image.
\subsubsection{Image Encoding and Decoding}Encoding is based on establishing image feature correspondences between images in node pairs. A coarse polygonal model (called a ?proxy?) of the environment is used to warp one image to the viewpoint of the other prior to image differencing.
Three different methods of decoding and image extraction have been proposed in this work.

\begin{enumerate}\item{Using a tree of M nodes where the only I-node is the root. Using O(log M) image additions (M = the height of the tree) is sufficient to extract an image. This method introduces a large error into the extraction process.}\item{Forcing I-nodes to be distributed throughout the tree using several techniques allows a reduction in both decompression time and reconstruction error at the expense of storage.}\item{Defining the residual of a P-node directly relative to the closest I-node reduces the number of image additions necessary to exactly 1 in all cases which can be done in constant time.}
\end{enumerate}
\subsection{Caching and GPU Based Optimization of Intermediate View Generation}``Real-Time Virtual Viewpoint Generation on the GPU for Scene Navigation" by Shanat Kolhatkar describes optimizations specifically for intermediate view generation using both caching and GPU based optimizations \cite{}.  
\subsubsection{Caching}In this work, the panoramas are modelled as a graph with neighbouring panoramas (in navigation) being adjacent within the graph. The primary caching technique proposed is to use a fixed buffer (or cache) size, and loading panoramas until the buffer is full. When the panorama being viewed changes, the buffer is updated by removing and adding new panoramas as necessary. 
\subsubsection{GPU Optimizations}As the flow of panoramas is pre-calculated, interpolation at the pixel level forms a set of mutually exclusive tasks which may be effectively parallelized. This work suggests using the GPU for viewpoint interpolation as well as for optical flow calculations. \subsection{Caching and Compression in 3D Interactive Walkthrough Generation}
``Plenoptic Stitching: A Scalable Method for Reconstructing 3D Interactive Walkthroughs" by Aliaga and Carlbom details several compression and caching techniques used in improving the performance of the plenoptic stitching framework proposed by the research work by the authors \cite{39}.In terms of compression, the authors recommend the use of a modified JPEG compression \cite{65} and for data structures Lempel-Ziv Compression \cite{Adams2008} is suggested. Three caches are proposed to dynamically load images and data. In particular, the use of bilinear interpolation is recommended for re-projecting captured images to cylindrical projections. 
Two Least Recently Used caches are for decompression. One is used to store compressed bit streams directly loaded from the hard disk, while the other stores decompressed groups of columns.
It is worth noting that the authors report an overall compression from 1494MB to 114MB which is approximately 13$\times$ compression.


