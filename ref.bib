@article{Adams2008,
author = {Adams, Andrew and Gelfand, Natasha and Pulli, Kari},
file = {:C$\backslash$:/Users/vipula/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Andrew Adams - Unknown - Viewfinder alignment.pdf:pdf},
journal = {Computer Graphics Forum},
number = {2},
pages = {597----606},
title = {{Viewfinder alignment}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.164.7091},
volume = {27},
year = {2008}
}
@inproceedings{Aliga001,
author = {Aliaga, D.G.},
booktitle = {Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001},
doi = {10.1109/ICCV.2001.937508},
isbn = {0-7695-1143-0},
keywords = {Accurate catadioptric calibration,Apertures,Calibration,Cameras,Computer vision,Image reconstruction,Lenses,Mirrors,Navigation,Radio control,Surges,beacon-based pose estimation algorithm,calibration,calibration model,center-of-projection,computer vision,ideal camera model,motion estimation,omnidirectional video cameras,orthographic lens,paraboloidal mirror,pose estimation,real-time pose estimation,room-size environments,video cameras},
language = {English},
pages = {127--134},
publisher = {IEEE Comput. Soc},
title = {{Accurate catadioptric calibration for real-time pose estimation in room-size environments}},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=937508},
volume = {1},
year = {2001}
}
@inproceedings{Aliaga05,
author = {Aliaga, D.G. and Carlbom, I.},
booktitle = {IEEE International Conference on Image Processing 2005},
doi = {10.1109/ICIP.2005.1529824},
isbn = {0-7803-9134-9},
keywords = {Compression algorithms,Decoding,Displays,Hardware,Image coding,Image reconstruction,Image storage,Image-based rendering,Pixel,Rendering (computer graphics),Transform coding,compression,compression scheme,data compression,hierarchical,image coding,image resampling,image sampling,image-based-rendering,motion compensation,motion-compensated schema,random access,rendering (computer graphics),spatial hierarchy,spatial image hierarchy},
language = {English},
pages = {I--609},
publisher = {IEEE},
title = {{A spatial image hierarchy for compression in image-based-rendering}},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=1529824},
volume = {1},
year = {2005}
}
@inproceedings{Aliaga2001,
address = {New York, New York, USA},
author = {Aliaga, Daniel G. and Carlbom, Ingrid},
booktitle = {Proceedings of the 28th annual conference on Computer graphics and interactive techniques},
doi = {10.1145/383259.383311},
file = {:C$\backslash$:/Users/vipula/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Aliaga, Carlbom - 2001 - Plenoptic Stitching A Scalable Method for Reconstructing 3D Interactive Walk Throughs.pdf:pdf},
isbn = {158113374X},
keywords = {image-based rendering,interactive walkthroughs,omnidirectional,plenoptic function,virtual environments},
month = aug,
pages = {443--450},
publisher = {ACM Press},
title = {{Plenoptic Stitching: A Scalable Method for Reconstructing 3D Interactive Walk Throughs}},
url = {http://dl.acm.org/citation.cfm?id=383259.383311},
year = {2001}
}
@inproceedings{Aliaga01,
author = {Aliaga, Daniel G. and Funkhouser, Thomas and Yanovsky, Dimah and Carlbom, Ingrid},
booktitle = {IEEE Computer Graphics and Applications},
pages = {331----338},
title = {{Sea of Images}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.14.6692},
year = {2001}
}
@inproceedings{Aliaga03,
address = {New York, New York, USA},
author = {Aliaga, Daniel G. and Yanovsky, Dimah and Funkhouser, Thomas and Carlbom, Ingrid},
booktitle = {Proceedings of the 2003 symposium on Interactive 3D graphics},
doi = {10.1145/641480.641511},
isbn = {1581136455},
keywords = {correspondence,image features,image-based rendering,interactive,reconstruction},
month = apr,
pages = {163},
publisher = {ACM Press},
title = {{Interactive image-based rendering using feature globalization}},
url = {http://dl.acm.org/citation.cfm?id=641480.641511},
year = {2003}
}
@inproceedings{Au2010,
author = {Au, Andrew},
title = {{Development of Multiview Image/Video Stitching Systems for Mobile Devices}},
url = {summit.sfu.ca/system/files/iritems1/12786/etd7625\_AAu.pdf},
year = {2010}
}
@article{Bao04,
author = {Bao, Ling and Intille, Stephen S.},
journal = {Pervasive Computing},
pages = {1--17},
title = {{Activity Recognition from User-Annotated Acceleration Data}},
volume = {3001},
year = {2004}
}
@article{Bay2008,
author = {Bay, Herbert and Ess, Andreas and Tuytelaars, Tinne and {Van Gool}, Luc},
doi = {10.1016/j.cviu.2007.09.014},
issn = {10773142},
journal = {Computer Vision and Image Understanding},
keywords = {Camera calibration,Feature description,Interest points,Local features,Object recognition},
month = jun,
number = {3},
pages = {346--359},
publisher = {Elsevier Science Inc.},
title = {{Speeded-Up Robust Features (SURF)}},
url = {http://dl.acm.org/citation.cfm?id=1370312.1370556},
volume = {110},
year = {2008}
}
@inproceedings{Bay2006,
address = {Berlin, Heidelberg},
author = {Bay, Herbert and Tuytelaars, Tinne and {Van Gool}, Luc},
booktitle = {Proceedings of the 9th European Conference on Computer Vision},
doi = {10.1007/11744023},
editor = {Leonardis, Ale\v{s} and Bischof, Horst and Pinz, Axel},
isbn = {978-3-540-33832-1},
month = may,
pages = {404--417},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{SURF: Speeded Up Robust Features}},
url = {http://dl.acm.org/citation.cfm?id=2094437.2094476},
volume = {3951},
year = {2006}
}
@book{Bebis2008,
address = {Berlin, Heidelberg},
doi = {10.1007/978-3-540-89646-3},
editor = {Bebis, George and Boyle, Richard and Parvin, Bahram and Koracin, Darko and Remagnino, Paolo and Porikli, Fatih and Peters, J\"{o}rg and Klosowski, James and Arns, Laura and Chun, Yu Ka and Rhyne, Theresa-Marie and Monroe, Laura},
isbn = {978-3-540-89645-6},
issn = {0302-9743},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Advances in Visual Computing}},
url = {http://www.springerlink.com/index/10.1007/978-3-540-89646-3},
volume = {5359},
year = {2008}
}
@inproceedings{BinHe2010,
abstract = {This paper concerns the problem of video stitching automatically in a multi-camera surveillance system. Previous approaches have used multiple calibrated cameras for large scale surveillance and monitoring. In this work, we formulate video stitching as a multi-image matching and blending problem, and use SURF to find matches of key points between images, employ homography matrix to calculate overlapping pixels and finally implement boundary resample algorithm to blend images. In addition, camera postures are estimated and fixed automatically according to key points' information. An experimental surveillance system we implemented confirmed the stability and efficiency of our algorithm.},
author = {{Bin He} and {Gang Zhao} and {Qifang Liu}},
booktitle = {2010 25th International Conference of Image and Vision Computing New Zealand},
doi = {10.1109/IVCNZ.2010.6148851},
isbn = {978-1-4244-9631-0},
issn = {2151-2191},
keywords = {Cameras,Image resolution,Monitoring,SURF,boundary resample algorithm,boundary resampling,camera pose estimation,camera posture estimation,cameras,homography matrix,image blending problem,image matching,key point information,matrix algebra,multi-camera,multicamera surveillance system,multiimage matching,panoramic video stitching,pose estimation,video stitching,video surveillance},
month = nov,
pages = {1--6},
publisher = {IEEE},
shorttitle = {Image and Vision Computing New Zealand (IVCNZ), 20},
title = {{Panoramic video stitching in multi-camera surveillance system}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6148851},
year = {2010}
}
@article{Bovik2002,
author = {Bovik, A.C. and Wang, Zhou},
doi = {10.1109/97.995823},
issn = {1070-9908},
journal = {IEEE Signal Processing Letters},
keywords = {Distortion measurement,Dynamic range,Humans,Image processing,Image quality,MATLAB implementation,Mathematical model,PSNR,Signal to noise ratio,Testing,Visual system,contrast distortion,image distortion,image processing,image processing applications,loss of correlation,luminance distortion,universal image quality index},
language = {English},
month = mar,
number = {3},
pages = {81--84},
publisher = {IEEE},
title = {{A Universal Image Quality Index}},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=995823},
volume = {9},
year = {2002}
}
@article{Brown2006,
author = {Brown, Matthew and Lowe, David G.},
doi = {10.1007/s11263-006-0002-3},
issn = {0920-5691},
journal = {International Journal of Computer Vision},
month = dec,
number = {1},
pages = {59--73},
title = {{Automatic Panoramic Image Stitching using Invariant Features}},
url = {http://link.springer.com/10.1007/s11263-006-0002-3},
volume = {74},
year = {2006}
}
@book{Burkhardt1998,
address = {Berlin, Heidelberg},
doi = {10.1007/BFb0054729},
editor = {Burkhardt, Hans and Neumann, Bernd},
isbn = {978-3-540-64613-6},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Computer Vision — ECCV’98}},
url = {http://link.springer.com/10.1007/BFb0054729},
volume = {1407},
year = {1998}
}
@book{Campilho2008,
address = {Berlin, Heidelberg},
doi = {10.1007/978-3-540-69812-8},
editor = {Campilho, Aur\'{e}lio and Kamel, Mohamed},
isbn = {978-3-540-69811-1},
issn = {0302-9743},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Image Analysis and Recognition}},
url = {http://www.springerlink.com/index/10.1007/978-3-540-69812-8},
volume = {5112},
year = {2008}
}
@inproceedings{Quicktime,
address = {New York, New York, USA},
author = {Chen, Shenchang Eric},
booktitle = {Proceedings of the 22nd annual conference on Computer graphics and interactive techniques - SIGGRAPH '95},
doi = {10.1145/218380.218395},
file = {:C$\backslash$:/Users/vipula/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen - 1995 - QuickTime VR.pdf:pdf},
isbn = {0897917014},
keywords = {environment maps,image registration,image warping,panoramic images,real-time display,view interpolation,virtual reality},
month = sep,
pages = {29--38},
publisher = {ACM Press},
title = {{QuickTime VR}},
url = {http://dl.acm.org/citation.cfm?id=218380.218395},
year = {1995}
}
@article{Chen2012,
author = {Chen, XiaoWu and Li, Qing and Li, Xin and Zhao, QinPing},
doi = {10.1007/s11432-011-4534-y},
issn = {1674-733X},
journal = {Science China Information Sciences},
month = feb,
number = {3},
pages = {600--614},
title = {{Video motion stitching using trajectory and position similarities}},
url = {http://link.springer.com/10.1007/s11432-011-4534-y},
volume = {55},
year = {2012}
}
@inproceedings{Chu11,
address = {New York, New York, USA},
author = {Chu, David and Lane, Nicholas D. and Lai, Ted Tsung-Te and Pang, Cong and Meng, Xiangying and Guo, Qing and Li, Fan and Zhao, Feng},
booktitle = {Proceedings of the 9th ACM Conference on Embedded Networked Sensor Systems - SenSys '11},
doi = {10.1145/2070942.2070949},
isbn = {9781450307185},
keywords = {classification,mobile devices,optimization,sensors,smartphones},
month = nov,
pages = {54},
publisher = {ACM Press},
title = {{Balancing energy, latency and accuracy for mobile sensor data classification}},
url = {http://dl.acm.org/citation.cfm?id=2070942.2070949},
year = {2011}
}
@misc{Dhand2009,
abstract = {A method and device for video stitching is presented. The invention determines one or more motion vectors indicative of changes in two consecutive images of a (video) sequence of images. It further determines a spatial correlation function by examining two images from two different videos obtained from adjacently placed cameras having an overlapping field of view and that are to be combined. The invention achieves a faster stitching of images by applying the correlation function for combining subsequent set/s of images, subject to a match value being in a predetermined range. The match-value is a value indicative of a change in the correlation function for the subsequent set of images that are to be combined. Said match value is determined according to sets of coordinate values which are indicative of an overlapping portion in the subsequent set of images that are to be combined and the correlation function. The sets of coordinate values are determined according to the motion vectors.},
author = {Dhand, Harsh and Sukumaran, Srihari},
month = oct,
title = {{Method and Device for Video Stitching}},
url = {http://www.google.com/patents/US20090257680},
year = {2009}
}
@inproceedings{El-Saban2009,
address = {New York, New York, USA},
author = {El-Saban, Motaz Ahmad and Refaat, Mahmoud and Kaheel, Ayman and Abdul-Hamid, Ahmed},
booktitle = {Proceedings of the seventeen ACM international conference on Multimedia - MM '09},
doi = {10.1145/1631272.1631493},
file = {:C$\backslash$:/Users/vipula/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/El-Saban et al. - 2009 - Stitching videos streamed by mobile phones in real-time.pdf:pdf},
isbn = {9781605586083},
keywords = {mobile video capturing,real-time,video stitching},
month = oct,
pages = {1009},
publisher = {ACM Press},
title = {{Stitching videos streamed by mobile phones in real-time}},
url = {http://dl.acm.org/citation.cfm?id=1631272.1631493},
year = {2009}
}
@misc{El-Saban,
author = {El-Saban, Motaz and Izz, Mostafa and Kaheel, Ayman},
title = {{Fast stitching of videos captured from freely moving devices by exploiting temporal redundancy}},
url = {http://research.microsoft.com/pubs/131912/icip2010\_time\_info\_v3.pdf},
urldate = {2015-04-30}
}
@misc{El-Sabana,
author = {El-Saban, Motaz and Izz, Mostafa and Kaheel, Ayman and Refaat, Mahmoud},
title = {{IMPROVED OPTIMAL SEAM SELECTION BLENDING FOR FAST VIDEO STITCHING OF VIDEOS CAPTURED FROM FREELY MOVING DEVICES}},
url = {http://research.microsoft.com/pubs/149871/paper\_blending\_cameraReady.pdf},
urldate = {2015-04-30}
}
@misc{Fehn,
author = {Fehn, C. and Kauff, P. and Schreer, O. and Sch\"{a}fer, R.},
title = {{INTERACTIVE VIRTUAL VIEW VIDEO FOR IMMERSIVE TV APPLICATIONS}},
url = {https://www.researchgate.net/profile/Oliver\_Schreer/publication/2373634\_Interactive\_Virtual\_View\_Video\_For\_Immersive\_TV\_Applications/links/0c960522d873cd2380000000.pdf},
urldate = {2015-05-08}
}
@article{Fischler81,
author = {Fischler, Martin A. and Bolles, Robert C.},
doi = {10.1145/358669.358692},
issn = {00010782},
journal = {Communications of the ACM},
keywords = {automated cartography,camera calibration,image matching,location determination,model fitting,scene analysis},
month = jun,
number = {6},
pages = {381--395},
publisher = {ACM},
title = {{Random sample consensus: a paradigm for model fitting with applications to image analysis and automated cartography}},
url = {http://dl.acm.org/citation.cfm?id=358669.358692},
volume = {24},
year = {1981}
}
@book{Forsyth2003,
author = {Forsyth, D.A. and Ponce, Jean},
edition = {2},
isbn = {0130851981},
keywords = {013608592X,Computer Books: General,Computer Vision,Computer Vision \& Pattern Recognition,Computer Vision: A Modern Approach (2nd Edition),Computers,Computers - General Information,Computers / Computer Vision \& Pattern Recognition,Computers / Intelligence (AI) \& Semantics,Computing: Textbooks \& Study Guides,David A. Forsyth,Intelligence (AI) \& Semantics,Jean Ponce,Pattern recognition,Pearson},
publisher = {Prentice Hall Professional Technical Reference},
title = {{Computer Vision: A Modern Approach}},
year = {2003}
}
@inproceedings{us2015,
author = {Gamage, Chandana and Dissanayake, Vipula and Herath, Sachini and Rasnayaka, Sanka and Seneviratna, Sachith and Vidanaarachchi, Rajith},
booktitle = {International Conference on Digital Image Computing: Techniques and Applications 2015},
title = {{Quantitative and Qualitative Evaluation of Performance and Robustness of Image Stitching Algorithms}},
year = {2015}
}
@inproceedings{Gottschalk96,
address = {New York, New York, USA},
author = {Gottschalk, S. and Lin, M. C. and Manocha, D.},
booktitle = {Proceedings of the 23rd annual conference on Computer graphics and interactive techniques - SIGGRAPH '96},
doi = {10.1145/237170.237244},
isbn = {0897917464},
keywords = {collision detection,contacts,hierarchical data structure,physically-based modeling,shape approximation,virtual prototyping},
month = aug,
pages = {171--180},
publisher = {ACM Press},
title = {{OBBTree}},
url = {http://dl.acm.org/citation.cfm?id=237170.237244},
year = {1996}
}
@misc{Guan,
author = {Guan, Hao and Smith, William A. P. and Ren, Peng},
title = {{View Stabilisation in Spherical Video}},
url = {https://fling.seas.upenn.edu/~luispuig/OMNIVIS/docs/papers/view.pdf},
urldate = {2015-05-08}
}
@misc{Haenselmann2006,
author = {Haenselmann, Thomas and Busse, Marcel and Kopf, Stephan and King, Thomas and Effelsberg, Wolfgang},
title = {{Multicamera Video-Stitching}},
url = {http://pi4.informatik.uni-mannheim.de/~kopf/publications/2006/Haenselmann\_2006a.pdf},
urldate = {2015-05-08},
year = {2006}
}
@misc{Haenselmann,
author = {Haenselmann, Thomas and Busse, Marcel and Kopf, Stephan and Wolfgang, Effelsberg and King, Thomas},
title = {{Multi camera Video-Stitching}},
url = {http://vca.ele.tue.nl/events/3Dworkshop2006/pdf/Haenselmann\_MulticameraVideoStitching.pdf},
urldate = {2015-04-29}
}
@article{Harris1988,
author = {Harris, Chris and Stephens, Mike},
file = {:C$\backslash$:/Users/vipula/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Harris, Stephens - 1988 - A combined corner and edge detector.pdf:pdf},
journal = {In Proc. of Fourth Alvey Vision Conference},
pages = {147----151},
title = {{A combined corner and edge detector}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.231.1604},
year = {1988}
}
@inproceedings{Huang2014,
abstract = {In this paper, a low-complexity video stitching algorithm and its system prototype are proposed. With the novel design, users can obtain a high-resolution, high quality and seamless 360-degree panoramic video immediately by stitching the images with overlapped regions. Most of the present works are focused on image stitching instead of video stitching. In the proposed design, we develop some novel methods to solve the problems encountered in video stitching. First, we provide a new blending method to remove the color difference in video stitching. Moreover, we avoid the moving objects in the overlapped area by using the dynamic seam adjustment scheme. Finally, we remove the drift problem and obtain a better visual quality while displaying the 360 degree panoramic video scenes. The implementation results show that the entire system achieves 4-channel D1 30fps real-time video stitching on an Intel i7 3930K CPU 2.3GHz machine with 8GB DDR3 memory and Linux Ubuntu 12.10 operation system.},
author = {Huang, Kai-Chen and Chien, Po-Yu and Chien, Cheng-An and Chang, Hsiu-Cheng and Guo, Jiun-In},
booktitle = {Technical Papers of 2014 International Symposium on VLSI Design, Automation and Test},
doi = {10.1109/VLSI-DAT.2014.6834863},
isbn = {978-1-4799-2776-0},
keywords = {360-degree panoramic video system design,Cameras,DDR3 memory,DRAM chips,Feature extraction,Image color analysis,Intel i7 3930K CPU machine,Lenses,Linux,Linux Ubuntu 12.10 operation system,Prototypes,Real-time systems,Streaming media,color difference removal,drift problem,dynamic seam adjustment scheme,image colour analysis,image stitching,low-complexity video stitching algorithm,system prototype,video signal processing,visual quality},
month = apr,
pages = {1--4},
publisher = {IEEE},
shorttitle = {VLSI Design, Automation and Test (VLSI-DAT), 2014 },
title = {{A 360-degree panoramic video system design}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6834863},
year = {2014}
}
@article{Keck,
author = {Keck, B. and Rakash, S.S.G. and Zoelzer, U.},
keywords = {3D planes,Image planes,matching points},
publisher = {ACTA Press},
title = {{Algorithm for Stitching of Video Sequences}},
url = {http://www.actapress.com/PaperInfo.aspx?PaperID=33929\&reason=500}
}
@article{Khan2012,
abstract = {In this study, the authors present quantitative quality assessment indices for measuring geometric and photometric qualities of stitched panoramic images, since both geometric and photometric qualities are important for obtaining a seamless panoramic image. For geometric quality assessment, our approach is based on the use of structural similarity (SSIM) index between the high-frequency information (HFI) of both geometrically corrected unstitched images and the stitched panoramic image. This measure is called `HFI`SSIM`. The complementary low-frequency information from the same pair of images is used for assessing the photometric quality of the stitched image using the spectral angle mapper and intensity magnitude ratio measures. The proposed quality metrics are tested on both synthetic and true datasets comprising of indoor and outdoor scenes. The results obtained, highlight the interest of using the proposed quantitative measures for assessing the quality of stitched panoramic images.},
author = {Khan, M.M. and Hafiz, R. and Cho, Y. and Qureshi, H.S. and Cha, J.},
doi = {10.1049/iet-ipr.2011.0641},
issn = {1751-9659},
journal = {IET Image Processing},
keywords = {SSIM index,angle mapper,geometric qualities,geometrically corrected unstitched images,high-frequency information,image processing,intensity magnitude ratio measures,photometric qualities,quantitative quality assessment,seamless panoramic image,stitched panoramic images,structural similarity index},
month = dec,
number = {9},
pages = {1348--1358},
shorttitle = {Image Processing, IET},
title = {{Quantitative quality assessment of stitched panoramic images}},
url = {http://digital-library.theiet.org/content/journals/10.1049/iet-ipr.2011.0641},
volume = {6},
year = {2012}
}
@article{Khan2012a,
abstract = {In this study, the authors present quantitative quality assessment indices for measuring geometric and photometric qualities of stitched panoramic images, since both geometric and photometric qualities are important for obtaining a seamless panoramic image. For geometric quality assessment, our approach is based on the use of structural similarity (SSIM) index between the high-frequency information (HFI) of both geometrically corrected unstitched images and the stitched panoramic image. This measure is called `HFI`SSIM`. The complementary low-frequency information from the same pair of images is used for assessing the photometric quality of the stitched image using the spectral angle mapper and intensity magnitude ratio measures. The proposed quality metrics are tested on both synthetic and true datasets comprising of indoor and outdoor scenes. The results obtained, highlight the interest of using the proposed quantitative measures for assessing the quality of stitched panoramic images.},
author = {Khan, M.M. and Hafiz, R. and Cho, Y. and Qureshi, H.S. and Cha, J.},
doi = {10.1049/iet-ipr.2011.0641},
issn = {1751-9659},
journal = {IET Image Processing},
keywords = {SSIM index,angle mapper,geometric qualities,geometrically corrected unstitched images,high-frequency information,image processing,intensity magnitude ratio measures,photometric qualities,quantitative quality assessment,seamless panoramic image,stitched panoramic images,structural similarity index},
month = dec,
number = {9},
pages = {1348--1358},
shorttitle = {Image Processing, IET},
title = {{Quantitative quality assessment of stitched panoramic images}},
url = {http://digital-library.theiet.org/content/journals/10.1049/iet-ipr.2011.0641},
volume = {6},
year = {2012}
}
@inproceedings{Kolhatkar2010,
abstract = {In this paper we present a method for achieving real-time view interpolation in a virtual navigation application that uses a collection of pre-captured panoramic views as a representation of the environment. In this context, viewpoint interpolation is essential to achieve smooth and realistic viewpoint transition while the user is moving from one panorama to another. In this proposed approach, view interpolation is achieved by first computing the optical flow field between a pair of adjacent panoramas. This flow field can then be used by the view morphing algorithm to generate, on-the-fly, virtual viewpoints in-between existing views. Realistic interpolation is obtained by taking into account both scene geometry and color information. To achieve real-time viewpoint interpolation, a GPU implementation of the viewpoint interpolation algorithm has been developed. We ran our algorithm on multiple interior and exterior scenes and we were able to produce smooth and realistic viewpoint transitions by generating virtual views at a rate of more than 300 panoramas per second.},
author = {Kolhatkar, Shanat and Lagani\`{e}re, Robert},
booktitle = {2010 Canadian Conference on Computer and Robot Vision},
doi = {10.1109/CRV.2010.14},
isbn = {978-1-4244-6963-5},
keywords = {Application software,Computer vision,Displays,Image motion analysis,Image reconstruction,Image-Based navigation,Interpolation,Layout,Navigation,Optical Flow,Optical computing,Robot vision systems,View Interpolation,View Morphing,color information,computer vision,coprocessors,exterior scene,graphics processing unit,image morphing,interior scene,interpolation,optical flow field,realtime virtual viewpoint generation,rendering (computer graphics),scene geometry,scene navigation,viewpoint interpolation},
pages = {55--62},
publisher = {IEEE},
shorttitle = {Computer and Robot Vision (CRV), 2010 Canadian Con},
title = {{Real-Time Virtual Viewpoint Generation on the GPU for Scene Navigation}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5479488},
year = {2010}
}
@inproceedings{Kolhatkar2010,
author = {Kolhatkar, Shanat and Lagani\`{e}re, Robert},
booktitle = {2010 Canadian Conference on Computer and Robot Vision},
doi = {10.1109/CRV.2010.14},
isbn = {978-1-4244-6963-5},
keywords = {Application software,Computer vision,Displays,Image motion analysis,Image reconstruction,Image-Based navigation,Interpolation,Layout,Navigation,Optical Flow,Optical computing,Robot vision systems,View Interpolation,View Morphing,color information,computer vision,coprocessors,exterior scene,graphics processing unit,image morphing,interior scene,interpolation,optical flow field,realtime virtual viewpoint generation,rendering (computer graphics),scene geometry,scene navigation,viewpoint interpolation},
language = {English},
pages = {55--62},
publisher = {IEEE},
title = {{Real-Time Virtual Viewpoint Generation on the GPU for Scene Navigation}},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=5479488},
year = {2010}
}
@book{Kumar2003,
address = {Berlin, Heidelberg},
doi = {10.1007/3-540-44839-X},
editor = {Kumar, Vipin and Gavrilova, Marina L. and Tan, Chih Jeng Kenneth and L’Ecuyer, Pierre},
isbn = {978-3-540-40155-1},
month = jun,
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Computational Science and Its Applications — ICCSA 2003}},
url = {http://link.springer.com/10.1007/3-540-44839-X},
volume = {2667},
year = {2003}
}
@article{Kwapisz11,
author = {Kwapisz, Jennifer R. and Weiss, Gary M. and Moore, Samuel A.},
doi = {10.1145/1964897.1964918},
issn = {19310145},
journal = {ACM SIGKDD Explorations Newsletter},
keywords = {accelerometer,activity recognition,cell phone,induction,sensor mining,sensors},
month = mar,
number = {2},
pages = {74},
publisher = {ACM},
title = {{Activity recognition using cell phone accelerometers}},
url = {http://dl.acm.org/citation.cfm?id=1964897.1964918},
volume = {12},
year = {2011}
}
@article{Lacey2000,
author = {Lacey, A. J. and Pinitkarn, N. and Thacker, N. A.},
file = {:C$\backslash$:/Users/vipula/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lacey, Pinitkarn, Thacker - Unknown - An Evaluation of the Performance of RANSAC Algorithms for Stereo Camera Calibration.pdf:pdf},
journal = {In Proceedings of the British Machine Vision Conference (BMVC)},
title = {{An Evaluation of the Performance of RANSAC Algorithms for Stereo Camera Calibration}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.116.3129},
year = {2000}
}
@misc{Lawler,
author = {Lawler, Richard},
title = {{'Virtual Reality Camera System' uses 6 Red Dragons to make 360-degree video magic}},
url = {http://www.engadget.com/2014/09/11/nextvr-red-virtual-reality-camera-system/},
urldate = {2015-05-08}
}
@inproceedings{LinqiangChen2010,
abstract = {This paper proposes a novel method to create wide-angle and high-resolution videos from video sequences by assembling the individual overlapping video frames. As we know, we register the frame sequences of different videos on the same plane using the perspective matrix and synthesize the overlapped region using a nonlinear blending method which is a time-consuming task; moreover, the scene depth is frequently varying for dynamic video content. Therefore, the projection transform should be changed as the dynamic content in real time. To tackle these problems, we propose a robust algorithm to estimate projection transform fast and blend in real time. Our algorithm includes two stages: the first stage is registration, an accuracy projection transform will get from the first frames of all videos; in the second stage, an optimized method will be used to make the projection transform changed as the sense depth verified in real-time, then a less-exhausted blending method is used to blend images and be gotten a high quality videos. Some real video stitching experiments are carried out, and our experiment results demonstrate that our algorithm can speed up video stitching and get high visual quality obviously.},
author = {{Linqiang Chen} and {Xiaoqiang Wang} and {Xu Liang}},
booktitle = {2010 International Conference On Computer Design and Applications},
doi = {10.1109/ICCDA.2010.5541517},
isbn = {978-1-4244-7164-5},
keywords = {Assembly,Computer graphics,Image fusion,Layout,Motion estimation,Optimization methods,Parameter estimation,RANSAC,Robustness,Video sequences,Videoconference,dynamic video content,high quality videos,high-resolution videos,image fusion,image sequences,nonlinear blending method,phase correlation,projection transform estimation,video sequences,video signal processing,video stitching,wide-angle videos},
month = jun,
pages = {V1--297--V1--301},
publisher = {IEEE},
shorttitle = {Computer Design and Applications (ICCDA), 2010 Int},
title = {{An effective video stitching method}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5541517},
volume = {1},
year = {2010}
}
@article{Lowe2004,
address = {Hingham, MA, USA},
author = {Lowe, David G},
doi = {10.1023/B:VISI.0000029664.99615.94},
issn = {0920-5691},
journal = {International Journal Computer Vision},
keywords = {image matching,invariant features,object recognition,scale invariance},
month = nov,
number = {2},
pages = {91--110},
publisher = {Kluwer Academic Publishers},
title = {{Distinctive Image Features from Scale-Invariant Keypoints}},
url = {http://dx.doi.org/10.1023/B:VISI.0000029664.99615.94},
volume = {60},
year = {2004}
}
@article{Lowe99,
author = {Lowe, David G.},
journal = {International Journal of Computer Vision},
title = {{SIFT: Scale Invarient Feature Transform}},
year = {1999}
}
@misc{Lowe2007,
author = {Lowe, David and Brown, Matthew},
title = {{Automatic Panoramic Image Stitching using Invariant Features}},
url = {https://www.cs.bath.ac.uk/brown/papers/ijcv2007.pdf},
urldate = {2015-04-29},
year = {2007}
}
@inproceedings{Lu2008,
abstract = {Virtual exhibition of museum plays an important role in education and popular science; yet a majority of current virtual reality technologies vary in the shortage of constructing a low-cost, desktop-based and networked 3D virtual museum. The paper proposes an XML-based scene description language for 3D virtual museum - XVM to meet the characteristics and requirements of 3D virtual museum. Based on the principle of separating the virtual environment and collection models, XVM effectively utilizes digital information of collection resources and reduces the network throughput to a certain extent. A virtual museum authoring and navigating system has been successfully implemented and applied in practice.},
author = {Lu, Wei and Zeng, Dinghao and Pan, Jingui},
booktitle = {ITI 2008 - 30th International Conference on Information Technology Interfaces},
doi = {10.1109/ITI.2008.4588451},
isbn = {978-953-7138-12-7},
issn = {1330-1012},
keywords = {3D virtual museum,Computer science,Internet,Layout,Navigation,Rendering (computer graphics),Solid modeling,Space technology,Three dimensional displays,Virtual environment,Virtual reality,XML,XML-based scene description language,XVM,authoring systems,exhibitions,humanities,specification languages,virtual environment,virtual museum,virtual museum authoring system,virtual museum exhibition,virtual reality,virtual reality technology},
month = jun,
pages = {445--450},
publisher = {IEEE},
shorttitle = {Information Technology Interfaces, 2008. ITI 2008.},
title = {{An XML-Based Scene Description Language for 3D Virtual Museum}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4588451},
year = {2008}
}
@inproceedings{Majumder1999,
address = {New York, New York, USA},
author = {Majumder, Aditi and Seales, W. Brent and Gopi, M. and Fuchs, Henry},
booktitle = {Proceedings of the seventh ACM international conference on Multimedia (Part 1) - MULTIMEDIA '99},
doi = {10.1145/319463.319485},
file = {:C$\backslash$:/Users/vipula/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Majumder et al. - 1999 - Immersive teleconferencing.pdf:pdf},
isbn = {1581131518},
month = oct,
pages = {169--178},
publisher = {ACM Press},
title = {{Immersive teleconferencing}},
url = {http://dl.acm.org/citation.cfm?id=319463.319485},
year = {1999}
}
@article{Mannos74,
author = {Mannos, J. and Sakrison, D.},
doi = {10.1109/TIT.1974.1055250},
issn = {0018-9448},
journal = {IEEE Transactions on Information Theory},
keywords = {Codes,Distortion measurement,Image coding,Image communication,Laboratories,Mathematical model,NASA,Performance evaluation,Rate-distortion,Rate-distortion theory,Transmitters},
language = {English},
month = jul,
number = {4},
pages = {525--536},
publisher = {IEEE},
title = {{The effects of a visual fidelity criterion of the encoding of images}},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=1055250},
volume = {20},
year = {1974}
}
@article{Martens1998,
author = {Martens, Jean-Bernard and Meesters, Lydia},
doi = {10.1016/S0165-1684(98)00123-6},
issn = {01651684},
journal = {Signal Processing},
keywords = {image dissimilarity,image quality metric,instrumental measures,objective image quality,subjective image quality,vision models},
month = nov,
number = {3},
pages = {155--176},
publisher = {Elsevier North-Holland, Inc.},
title = {{Image Dissimilarity}},
url = {http://dl.acm.org/citation.cfm?id=306933.306937},
volume = {70},
year = {1998}
}
@inproceedings{Martin10,
address = {New York, New York, USA},
author = {Martin, Eladio and Vinyals, Oriol and Friedland, Gerald and Bajcsy, Ruzena},
booktitle = {Proceedings of the international conference on Multimedia},
doi = {10.1145/1873951.1874078},
isbn = {9781605589336},
keywords = {indoor localization,smart phones},
month = oct,
pages = {787},
publisher = {ACM Press},
title = {{Precise indoor localization using smart phones}},
url = {http://dl.acm.org/citation.cfm?id=1873951.1874078},
year = {2010}
}
@misc{techcrunch,
author = {Merel, Tim},
title = {{Augmented And Virtual Reality To Hit \$150 Billion, Disrupting Mobile By 2020}},
url = {http://techcrunch.com/2015/04/06/augmented-and-virtual-reality-to-hit-150-billion-by-2020/\#.fvqw3j:wdZy},
urldate = {2015-05-08}
}
@inproceedings{Mikolajczyk2001,
author = {Mikolajczyk, K. and Schmid, C.},
booktitle = {Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001},
doi = {10.1109/ICCV.2001.937561},
isbn = {0-7695-1143-0},
keywords = {Detectors,Filters,Harris interest point detector,Image databases,Indexing,Laplace equations,Layout,Lighting,Robustness,affine illumination changes,computer vision,database indexing,indexing,multi-scale representation,normalized derivatives,scale invariant interest points,scale invariant points},
language = {English},
pages = {525--531},
publisher = {IEEE Comput. Soc},
title = {{Indexing based on scale invariant interest points}},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=937561},
volume = {1},
year = {2001}
}
@inproceedings{Nielsen2002,
abstract = {We describe algorithms for authoring and viewing high-resolution immersive videos. Given a set of cameras designed to be aligned more or less at the same nodal point, we first present a process for stitching seamlessly synchronized streams of videos into a single immersive video corresponding to the video of the abstract multi-head camera. We describe a general registration technique on to geometric envelopes based on minimizing a novel appropriate objective function, and detail our compounded image synthesis algorithm of multi-head cameras. Several new environment maps with low discrepancy are presented. Finally, we give details of the viewer implementation. Experimental results on both real and synthetic immersive videos are shown.},
author = {Nielsen, F.},
booktitle = {Proceedings. International Conference on Information Technology: Coding and Computing},
doi = {10.1109/ITCC.2002.1000397},
isbn = {0-7695-1506-1},
keywords = {Cameras,Computer graphics,Computer science,Image generation,Layout,Motion pictures,Rendering (computer graphics),Streaming media,Videos,Virtual environment,authoring systems,camera alignment,compounded image synthesis algorithm,discrepancy,environment maps,geometric envelopes,geometry,high-resolution full spherical videos,high-resolution immersive video,image registration,image registration technique,image resolution,minimisation,multi-head cameras,nodal point,objective function minimization,seamlessly synchronized video stream stitching,synchronisation,video authoring,video cameras,video signal processing,video viewing,viewer implementation,virtual reality},
pages = {260--267},
publisher = {IEEE Comput. Soc},
shorttitle = {Information Technology: Coding and Computing, 2002},
title = {{High resolution full spherical videos}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1000397},
year = {2002}
}
@misc{Nielsen,
author = {Nielsen, Frank},
title = {{On Representing Spherical Videos}},
url = {http://www.sonycsl.co.jp/person/nielsen/spatialmedia/cvpr2001-nielsen.pdf},
urldate = {2015-05-08}
}
@article{abhijit06,
author = {Ogale, Abhijit S. and Aloimonos, Yiannis},
doi = {10.1007/s11263-006-8890-9},
issn = {0920-5691},
journal = {International Journal of Computer Vision},
month = jul,
number = {1},
pages = {9--25},
publisher = {Kluwer Academic Publishers},
title = {{A Roadmap to the Integration of Early Visual Modules}},
url = {http://dl.acm.org/citation.cfm?id=1188053.1188108},
volume = {72},
year = {2006}
}
@misc{OZKESKIN,
author = {OZKESKIN, Emrah Emre and TUNC, Tuncay},
title = {{SPHERICAL VIDEO RECORDING AND POSSIBLE INTERACTIVE EDUCATIONAL USES}},
url = {http://ijonte.org/FileUpload/ks63207/File/6..pdf},
urldate = {2015-05-08}
}
@misc{Pan2011,
abstract = {The invention discloses an optimized video stitching method, comprising: inputting predefined pattern images; proceeding with a transformation which combines planar and cylindrical transformation; proceeding with a merging calculation which combines linear difference merging and alpha blending calculation; and proceeding with a horizontal stitching processing by putting the processed images horizontally together into one seamless wide-angle image. The optimized video stitching method according to the invention further comprises a camera position calibration flow comprising: finding a planar matrix by using predefined pattern images; proceeding with a planar transformation of image; proceeding with an image registration by using a block matching method to find out the stitching points on the planar surface; and proceeding with a cylindrical transformation by transforming the stitching points from the planar surface to cylindrical surface.},
author = {Pan, Patrick and Mitsushita, Tatsumi and Lin, Christine and Kuo, Benjamin},
month = jul,
title = {{Optimized video stitching method}},
url = {http://www.google.com/patents/US7978931},
year = {2011}
}
@article{panchal2013,
author = {Panchal, PM and Panchal, SR and Shah, SK},
journal = {International Journal of Innovative Research in Computer and Communication Engineering},
number = {2},
pages = {323--327},
title = {{A Comparison of SIFT and SURF}},
volume = {1},
year = {2013}
}
@techreport{Pedersen2011,
author = {Pedersen, Jacob Toft},
title = {{SURF : Feature Detection \& Description}},
year = {2011}
}
@book{Poynton:1996:TID:233439,
address = {New York, NY, USA},
author = {Poynton, Charles},
isbn = {0-471-12253-X},
publisher = {John Wiley \& Sons, Inc.},
title = {{A Technical Introduction to Digital Video}},
year = {1996}
}
@article{Ravi05,
author = {Ravi, Nishkam and Dandekar, Nikhil and Mysore, Preetham and Littman, Michael L.},
isbn = {1-57735-236-x},
month = jul,
pages = {1541--1546},
publisher = {AAAI Press},
title = {{Activity recognition from accelerometer data}},
url = {http://dl.acm.org/citation.cfm?id=1620092.1620107},
year = {2005}
}
@book{Schoeffmann2012,
address = {Berlin, Heidelberg},
doi = {10.1007/978-3-642-27355-1},
editor = {Schoeffmann, Klaus and Merialdo, Bernard and Hauptmann, Alexander G. and Ngo, Chong-Wah and Andreopoulos, Yiannis and Breiteneder, Christian},
isbn = {978-3-642-27354-4},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Advances in Multimedia Modeling}},
url = {http://www.springerlink.com/index/10.1007/978-3-642-27355-1},
volume = {7131},
year = {2012}
}
@inproceedings{Shimizu2006,
abstract = {We propose a fast video stitching method based on global motion tracking for motion-compensated frames, which can construct high definition or panorama video from standard definition video streams. Our method consists of two stages. The first stage calculates projection matrix between stitched frames coarsely by compensating for global motion of each input video stream. Since the result of the first stage may include some matching error, fine adjustment is performed in the second stage.},
author = {Shimizu, T. and Yoneyama, A. and Takishima, Y.},
booktitle = {2006 Digest of Technical Papers International Conference on Consumer Electronics},
doi = {10.1109/ICCE.2006.1598366},
isbn = {0-7803-9459-3},
keywords = {Cameras,DVD,Feature extraction,High definition video,Laboratories,Research and development,Streaming media,Tracking,Video compression,Video sequences,compressed video streams,data compression,matching error,matrix algebra,motion compensation,motion tracking,motion-compensated frames,panorama video,projection matrix,video coding,video stitching method,video streaming},
pages = {173--174},
publisher = {IEEE},
shorttitle = {Consumer Electronics, 2006. ICCE '06. 2006 Digest },
title = {{A Fast Video Stitching Method for Motion-Compensated Frames in Compressed Video Streams}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1598366},
year = {2006}
}
@article{Simon2007,
author = {{Simon A. J. Winder}, Matthew Brown},
journal = {International Conference on Computer Vision and Pattern Recognition},
title = {{Learning local image descriptors}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.86.8259},
year = {2007}
}
@inproceedings{Soper2011,
author = {Soper, Timothy D. and Chandler, John E. and Porter, Michael P. and Seibel, Eric J.},
booktitle = {SPIE Medical Imaging},
doi = {10.1117/12.878299},
editor = {Wong, Kenneth H. and {Holmes III}, David R.},
month = mar,
pages = {796417--796417--12},
publisher = {International Society for Optics and Photonics},
title = {{<title>Constructing spherical panoramas of a bladder phantom from endoscopic video using bundle adjustment</title>}},
url = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?articleid=726114},
year = {2011}
}
@article{Starck1994,
author = {Starck, Jean-Luc and Murtagh, Fionn},
issn = {0004-6361},
journal = {Astronomy and Astrophysics},
keywords = {Algorithms,Analysis (Mathematics),Image Enhancement,Image Processing,Low Pass Filters,Noise Reduction,Transformations (Mathematics),Wavelet Analysis},
language = {en},
month = aug,
pages = {342--348},
title = {{Image restoration with noise suppression using the wavelet transform}},
url = {http://cdsads.u-strasbg.fr/abs/1994A\%26A...288..342S},
volume = {288},
year = {1994}
}
@inproceedings{Steedly2005,
abstract = {We present an automatic and efficient method to register and stitch thousands of video frames into a large panoramic mosaic. Our method preserves the robustness and accuracy of image stitchers that match all pairs of images while utilizing the ordering information provided by video. We reduce the cost of searching for matches between video frames by adaptively identifying key frames based on the amount of image-to-image overlap. Key frames are matched to all other key frames, but intermediate video frames are only matched to temporally neighboring key frames and intermediate frames. Image orientations can be estimated from this sparse set of matches in time quadratic to cubic in the number of key frames but only linear in the number of intermediate frames. Additionally, the matches between pairs of images are compressed by replacing measurements within small windows in the image with a single representative measurement. We show that this approach substantially reduces the time required to estimate the image orientations with minimal loss of accuracy. Finally, we demonstrate both the efficiency and quality of our results by registering several long video sequences},
author = {Steedly, D. and Pal, C. and Szeliski, R.},
booktitle = {Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1},
doi = {10.1109/ICCV.2005.86},
isbn = {0-7695-2334-X},
issn = {1550-5499},
keywords = {Computational efficiency,Computer vision,Costs,Digital cameras,Dynamic range,Image coding,Robustness,Software quality,Video compression,Video sequences,image orientations,image registration,image sequences,image stitchers,image-to-image overlap,panoramic mosaics,video frames,video registration,video sequences},
pages = {1300--1307 Vol. 2},
publisher = {IEEE},
shorttitle = {Computer Vision, 2005. ICCV 2005. Tenth IEEE Inter},
title = {{Efficiently registering video into panoramic mosaics}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1544870},
volume = {2},
year = {2005}
}
@misc{Steuart2008,
abstract = {The digital 3D/360° camera system is an omnidirectional stereoscopic device for capturing image data that may be used to create a 3-dimensional model for presenting a 3D image, a 3D movie, or 3D animation. The device uses multiple digital cameras, arranged with overlapping fields of view, to capture image data covering an entire 360° scene. The data collected by one, or several, digital 3D/360° camera systems can be used to create a 3D model of a 360° scene by using triangulation of the image data within the overlapping fields of view.},
author = {Steuart, Leonard P.},
month = dec,
title = {{Digital 3D/360 degree camera system}},
url = {http://www.google.com/patents/US7463280},
year = {2008}
}
@article{Sun10,
author = {Sun, Lin and Zhang, Daqing and Li, Bin and Guo, Bin and Li, Shijian},
isbn = {3-642-16354-8, 978-3-642-16354-8},
keywords = {SVM,accelerometer,activity recognition,mobile phone},
month = oct,
pages = {548--562},
publisher = {Springer-Verlag},
title = {{Activity recognition on an accelerometer embedded mobile phone with varying positions and orientations}},
url = {http://dl.acm.org/citation.cfm?id=1929661.1929712},
year = {2010}
}
@techreport{Szeliski2004,
author = {Szeliski, Richard},
title = {{Image Alignment and Stitching: A Tutorial}},
url = {http://graphics.cs.cmu.edu/courses/15-463/2004\_fall/www/Papers/MSR-TR-2004-92-Sep27.pdf},
year = {2004}
}
@article{Szeliski,
author = {Szeliski, Richard},
file = {:C$\backslash$:/Users/vipula/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Szeliski - Unknown - Image alignment and stitching A tutorial.pdf:pdf},
title = {{Image alignment and stitching: A tutorial}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.130.6691}
}
@inproceedings{Tennoe2013,
abstract = {High resolution, wide field of view video generated from multiple camera feeds has many use cases. However, processing the different steps of a panorama video pipeline in real-time is challenging due to the high data rates and the stringent requirements of timeliness. We use panorama video in a sport analysis system where video events must be generated in real-time. In this respect, we present a system for real-time panorama video generation from an array of low-cost CCD HD video cameras. We describe how we have implemented different components and evaluated alternatives. We also present performance results with and without co-processors like graphics processing units (GPUs), and we evaluate each individual component and show how the entire pipeline is able to run in real-time on commodity hardware.},
author = {Tennoe, Marius and Helgedagsrud, Espen and Naess, Mikkel and Alstad, Henrik Kjus and Stensland, Hakon Kvale and Gaddam, Vamsidhar Reddy and Johansen, Dag and Griwodz, Carsten and Halvorsen, Pal},
booktitle = {2013 IEEE International Symposium on Multimedia},
doi = {10.1109/ISM.2013.21},
isbn = {978-1-4799-2171-3},
keywords = {CCD image sensors,Cameras,GPU,Graphics processing units,Image color analysis,Pipelines,Real-time panorama video,Real-time systems,Streaming media,Yarn,camera array,commodity hardware,coprocessors,graphics processing units,image resolution,low-cost CCD HD video camera array,pipeline processing,real-time panorama video generation,real-time panorama video pipeline implementation,real-time panorama video pipeline processing,soccer system,sport,sport analysis system,system integration,video cameras,video events generated,video signal processing},
month = dec,
pages = {76--83},
publisher = {IEEE},
shorttitle = {Multimedia (ISM), 2013 IEEE International Symposiu},
title = {{Efficient Implementation and Processing of a Real-Time Panorama Video Pipeline}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6746472},
year = {2013}
}
@article{Tomasi91,
author = {Tomasi, Carlo and Kanade, Takeo},
journal = {International Journal of Computer Vision},
title = {{Detection and Tracking of Point Features}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.45.5770},
year = {1991}
}
@article{Triggs99,
author = {Triggs, Bill and McLauchlan, Philip F. and Hartley, Richard I. and Fitzgibbon, Andrew W.},
isbn = {3-540-67973-1},
month = sep,
pages = {298--372},
publisher = {Springer-Verlag},
title = {{Bundle Adjustment - A Modern Synthesis}},
url = {http://dl.acm.org/citation.cfm?id=646271.685629},
year = {1999}
}
@inproceedings{Tutenel2010,
author = {Tutenel, Tim and Smelik, Ruben and Bidarra, Rafael and de Kraker, Klaas Jan},
booktitle = {AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment},
title = {{A Semantic Scene Description Language for Procedural Layout Solving Problems}},
year = {2010}
}
@article{Tzavidas2005,
abstract = {Traditional visual communication systems convey only two-dimensional (2-D) fixed field-of-view (FOV) video information. The viewer is presented with a series of flat, nonstereoscopic images, which fail to provide a realistic sense of depth. Furthermore, traditional video is restricted to only a small part of the scene, based on the director's discretion and the user is not allowed to "look around" in an environment. The objective of this work is to address both of these issues and develop new techniques for creating stereo panoramic video sequences. A stereo panoramic video sequence should be able to provide the viewer with stereo vision at any direction (complete 360-degree FOV) at video rates. In this paper, we propose a new technique for creating stereo panoramic video using a multicamera approach, thus creating a high-resolution output. We present a setup that is an extension of a previously known approach, developed for the generation of still stereo panoramas, and demonstrate that it is capable of creating high-resolution stereo panoramic video sequences. We further explore the limitations involved in a practical implementation of the setup, namely the limited number of cameras and the nonzero physical size of real cameras. The relevant tradeoffs are identified and studied.},
author = {Tzavidas, S. and Katsaggelos, A.K.},
doi = {10.1109/TMM.2005.854430},
issn = {1520-9210},
journal = {IEEE Transactions on Multimedia},
keywords = {Cameras,Circular projections,Engine cylinders,Image processing,Layout,Mirrors,Stereo vision,Two dimensional displays,Video sequences,Video signal processing,Visual communication,field-of-view video information,multicamera approach,panoramic video,stereo image processing,stereo panoramic video sequence,stereo vision,video signal processing,visual communication system},
month = oct,
number = {5},
pages = {880--890},
shorttitle = {Multimedia, IEEE Transactions on},
title = {{A multicamera setup for generating stereo panoramic video}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1510635},
volume = {7},
year = {2005}
}
@misc{Unity2005,
author = {Unity},
title = {{Unity - Game Engine}},
url = {http://unity3d.com/},
year = {2005}
}
@article{Uyttendaele2004,
abstract = {Interactive scene walkthroughs have long been an important computer graphics application area. More recently, researchers have developed techniques for constructing photorealistic 3D architectural models from real-world images. We present an image-based rendering system that brings us a step closer to a compelling sense of being there. Whereas many previous systems have used still photography and 3D scene modeling, we avoid explicit 3D reconstruction because it tends to be brittle. Our system is not the first to propose interactive video-based tours. We believe, however, that our system is the first to deliver fully interactive, photorealistic image-based tours on a personal computer at or above broadcast video resolutions and frame rates. Moreover, to our knowledge, no other tour provides the same rich set of interactions or visually complex environments.},
author = {Uyttendaele, M. and Criminisi, A. and Winder, S. and Szeliski, R. and Hartley, R.},
doi = {10.1109/MCG.2004.1297011},
issn = {0272-1716},
journal = {IEEE Computer Graphics and Applications},
keywords = {3D scene modeling,Application software,Broadcasting,Computer Graphics,Computer Simulation,Computer graphics,Computer-Assisted,Environment,Exploratory Behavior,Image Interpretation,Image reconstruction,Image resolution,Information Storage and Retrieval,Layout,Microcomputers,Multimedia,Multimedia communication,Online Systems,Photography,Rendering (computer graphics),User-Computer Interface,Video Recording,broadcast video resolution,computer graphics application area,data visualisation,image-based rendering system,interactive scene,interactive systems,interactive video-based tour,photorealistic 3D architectural model,real-world images,realistic images,rendering (computer graphics),solid modelling,three-dimensional displays,visually complex environments},
month = may,
number = {3},
pages = {52--63},
shorttitle = {Computer Graphics and Applications, IEEE},
title = {{Image-based interactive exploration of real-world environments}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1297011},
volume = {24},
year = {2004}
}
@book{Vince95,
author = {Vince, John A.},
isbn = {978-0201876871},
pages = {388},
title = {{Virtual Reality Systems}},
year = {1995}
}
@book{Wald2002,
abstract = {This book establishes the fundamentals (particularly definitions and architectures) in data fusion. The second part of the book is devoted to methods for the fusion of images. It offers an in-depth presentation of standard and advanced methods for the fusion of multi-modality images.},
author = {Wald, Lucien},
isbn = {291176238X},
pages = {198},
publisher = {Presses des MINES},
title = {{Data Fusion: Definitions and Architectures : Fusion of Images of Different Spatial Resolutions}},
url = {https://books.google.com/books?hl=en\&lr=\&id=JOQ6elyzq-8C\&pgis=1},
year = {2002}
}
@article{wallace92,
author = {Wallace, G.K.},
doi = {10.1109/30.125072},
issn = {00983063},
journal = {IEEE Transactions on Consumer Electronics},
keywords = {Baseline method,CCITT,Costs,DCT,Digital images,Displays,Facsimile,Gray-scale,ISO,ISO standards,Image coding,Image storage,JPEG,Joint Photographic Experts Group,Standards development,TV standard,Transform coding,coding,color,continuous-tone still images,data compression,discrete cosine transform,grayscale,international compression standard,lossless compression,lossy compression,picture processing,predictive method,still picture compression standard,television standards,transforms},
language = {English},
number = {1},
pages = {xviii--xxxiv},
publisher = {IEEE},
title = {{The JPEG still picture compression standard}},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=125072},
volume = {38},
year = {1992}
}
@article{Wang2004,
author = {Wang, Z. and Bovik, A.C. and Sheikh, H.R. and Simoncelli, E.P.},
doi = {10.1109/TIP.2003.819861},
issn = {1057-7149},
journal = {IEEE Transactions on Image Processing},
keywords = {Algorithms,Automated,Computer-Assisted,Data Interpretation,Data mining,Degradation,Humans,Hypermedia,Image Enhancement,Image Interpretation,Image quality,Indexes,Information Storage and Retrieval,JPEG,JPEG2000,Layout,Models,Pattern Recognition,Quality Control,Quality assessment,Reproducibility of Results,Sensitivity and Specificity,Signal Processing,Statistical,Subtraction Technique,Transform coding,Visual perception,Visual system,data compression,distorted image,error sensitivity,error visibility,human visual perception,human visual system,image coding,image compression,image database,perceptual image quality assessment,reference image,structural information,structural similarity index,visual perception},
language = {English},
month = apr,
number = {4},
pages = {600--612},
publisher = {IEEE},
title = {{Image Quality Assessment: From Error Visibility to Structural Similarity}},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=1284395},
volume = {13},
year = {2004}
}
@book{Weber1996,
abstract = {The first edition of this book (E.H. Weber: The Sense of Touch, Academic Press, 1978) has long been out of print. But interest in Weber's work continues and this revised edition commemorates the bicentenary of his birth.The introduction has been expanded to include further information on Weber's life and times, and on recent research relevant to Weber's own work. The translations of Weber's main works of psychological interest (De Tactu and Der Tastsinn und das Gemeingefuhl) contain minor changes, and the footnotes and indexes have been updated.The reader will find here much more than those topics for which Weber is best known - the two-point threshold, experiments on weight discrimination and a statement of what is now called Weber's Law. Weber also made interesting remarks on many aspects of sensory psychology - on left-right asymmetry in sensitivity, on visual resolution, the binocular combination of colours, the moon illusion, on summation, inhibition and adaptation in sensory systems, on the difference between simultaneous and successive presentations, on selective attention, the externalisation of sensations and the difference between sensation and perception. As a scientist, Weber was working in the new area of experimental psychology; as a philosopher, he bridged the gap between philosophy and experiment. His work remains of interest to historians of science, to philosophers and to sensory psychologists.},
author = {Weber, Ernst Heinrich and Ross, Helen Elizabeth and Murray, David J.},
isbn = {0863774210},
pages = {260},
publisher = {Psychology Press},
title = {{E.H. Weber on the Tactile Senses}},
url = {https://books.google.com/books?id=xEd8JglYzFwC\&pgis=1},
year = {1996}
}
@article{Willemsen14,
author = {Willemsen, Thomas and Keller, F. and Sternberg, Harald},
journal = {International Conference on Information Fusion},
keywords = {Accelerometers,Floors,Global Navigation Satellite System,Kalman filter,Kalman filters,MEMS,MEMS low-cost sensor,Magnetic sensors,Navigation,Particle filters,indoor GNSS signal,indoor communication,indoor navigation,microelectro mechanical system sensor,microsensors,particle filter,particle filtering (numerical methods),position determination,position estimation,position estimator,satellite navigation,smart phones,smartphone,smartphone based indoor localization system},
language = {English},
pages = {1--8},
publisher = {IEEE},
title = {{Concept for building a smartphone based indoor localization system}},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=6916148},
year = {2014}
}
@misc{Xiao-qiang2011,
author = {Xiao-qiang, WANG and Lin-qiang, CHEN and Xu, LIANG},
title = {{Method of Real Time Automatic Video Stitching--《Computer Engineering》2011年05期}},
url = {http://en.cnki.com.cn/Article\_en/CJFDTOTAL-JSJC201105101.htm},
urldate = {2015-05-08},
year = {2011}
}
@article{Xiong2010,
abstract = {This paper addresses the problem of creating high-resolution and high-quality panoramic images from long image sequences with very different colors and luminance in source images. A fast stitching approach is proposed for combining a set of source images into a panoramic image using little memory, and implemented on mobile phones. In this approach, color correction reduces color differences of source images and balances colors and luminance in the whole image sequence, dynamic programming finds optimal seams in overlapping areas between adjacent images and merges them together, and image blending further smoothens color transitions and hides visible seams and stitching artifacts. A sequential panorama stitching procedure constructs panoramic images. The advantages include fast processing speed using dynamic programming for optimal seam finding, reducing memory needs by using the sequential panorama stitching, and improved quality of image labeling and blending due to the use of color correction. The approach has been tested with different image sequences and it works well on both indoor and outdoor scenes.},
author = {Xiong, Yingen and Pulli, Kari},
doi = {10.1109/TCE.2010.5505931},
issn = {0098-3063},
journal = {IEEE Transactions on Consumer Electronics},
keywords = {Application software,Cameras,Color,Dynamic programming,Image sequences,Labeling,Layout,Mobile computing,Mobile handsets,Mobile panorama, image stitching, fast labeling, i,Smoothing methods},
month = may,
number = {2},
pages = {298--306},
shorttitle = {Consumer Electronics, IEEE Transactions on},
title = {{Fast panorama stitching for high-quality panoramic images on mobile phones}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5505931},
volume = {56},
year = {2010}
}
@inproceedings{Zhang2009,
abstract = {A new video stitch algorithm based on dynamic foreground extraction is proposed in this paper. The algorithm is found on static image mosaic. To solve the problem caused by the moving objects in the videos, the background images are extracted. Using the featured-based method to get the transformation matrix between the background images, a wide background video is stitched up. This method greatly improves the efficiency of the algorithm. Besides, the moving foreground objects are extracted and the comparability between objects in the overlap area of different videos is computed to decide whether they are the same object and which to be reserved in the wide background video. As a result, the ghost is removed. Experimental results show that it is a highly-matched and robust video stitch algorithm, and can basically achieve real-time stitch.},
author = {Zhang, Yuan and Jia, Kebin and Liu, Pengyu},
booktitle = {International Congress on Image and Signal Processing},
doi = {10.1109/CISP.2009.5305636},
isbn = {978-1-4244-4129-7},
keywords = {Cameras,Clustering algorithms,Control engineering,Data mining,Educational institutions,Feature extraction,Heuristic algorithms,Image registration,Pixel,Robustness,dynamic foreground extraction,image registration,image segmentation,moving objects,static image mosaic,transformation matrix,video stitch algorithm},
month = oct,
pages = {1--5},
publisher = {IEEE},
shorttitle = {Image and Signal Processing, 2009. CISP '09. 2nd I},
title = {{Video Stitch Algorithm Based on Dynamic Foreground Extraction}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5305636},
year = {2009}
}
@book{Zheng2008,
address = {Berlin, Heidelberg},
author = {Zheng, Mai and Chen, Xiaolin and Guo, Li},
doi = {10.1007/978-3-540-89646-3},
editor = {Bebis, George and Boyle, Richard and Parvin, Bahram and Koracin, Darko and Remagnino, Paolo and Porikli, Fatih and Peters, J\"{o}rg and Klosowski, James and Arns, Laura and Chun, Yu Ka and Rhyne, Theresa-Marie and Monroe, Laura},
isbn = {978-3-540-89645-6},
issn = {0302-9743},
month = dec,
pages = {420--429},
publisher = {Springer Berlin Heidelberg},
title = {{Advances in Visual Computing}},
url = {http://dl.acm.org/citation.cfm?id=1486099.1486146},
volume = {5359},
year = {2008}
}
@inproceedings{Zheng2008,
address = {Berlin, Heidelberg},
author = {Zheng, Mai and Chen, Xiaolin and Guo, Li},
booktitle = {International Symposium on Advances in Visual Computing},
doi = {10.1007/978-3-540-89646-3\_41},
isbn = {978-3-540-89645-6},
pages = {420--429},
publisher = {Springer-Verlag},
series = {ISVC '08},
title = {{Stitching Video from Webcams}},
url = {http://dx.doi.org/10.1007/978-3-540-89646-3\_41},
year = {2008}
}
@article{Zhu2013,
abstract = {Video panoramic image stitching is extremely time-consuming among other challenges. We present a new algorithm: (i) Improved, self-adaptive selection of Harris corners. The successful stitching relies heavily on the accuracy of corner selection. We fragment each image into numerous regions and select corners within each region according to the normalized variance of region grayscales. Such a selection is self-adaptive and guarantees that corners are distributed proportional to region texture information. The possible clustering of corners is also avoided. (ii) Multiple-constraint corner matching. The traditional Random Sample Consensus (RANSAC) algorithm is inefficient, especially when handling a large number of images with similar features. We filter out many inappropriate corners according to their position information, and then generate candidate matching pairs based on grayscales of adjacent regions around corners. Finally we apply multiple constraints on every two pairs to remove incorrectly matched pairs. By a significantly reduced number of iterations needed in RANSAC, the stitching can be performed in a much more efficient manner. Experiments demonstrate that (i) our corner matching is four times faster than normalized cross-correlation function (NCC) rough match in RANSAC and (ii) generated panoramas feature a smooth transition in overlapping image areas and satisfy real-time human visual requirements.},
author = {Zhu, Minchen and Wang, Weizhi and Liu, Binghan and Huang, Jingshan},
doi = {10.1371/journal.pone.0081182},
file = {:C$\backslash$:/Users/vipula/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhu et al. - 2013 - Efficient video panoramic image stitching based on an improved selection of Harris corners and a multiple-constraint.pdf:pdf},
issn = {1932-6203},
journal = {PloS one},
keywords = {Algorithms,Computer-Assisted,Humans,Image Processing,Video Recording},
month = jan,
number = {12},
pmid = {24324675},
title = {{Efficient video panoramic image stitching based on an improved selection of Harris corners and a multiple-constraint corner matching.}},
url = {http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0081182},
volume = {8},
year = {2013}
}
@article{Ziv77,
author = {Ziv, J. and Lempel, A.},
doi = {10.1109/TIT.1977.1055714},
issn = {0018-9448},
journal = {IEEE Transactions on Information Theory},
keywords = {Books,Compression algorithms,Data compression,Data processing,Displays,Information theory,Jacobian matrices,Sequential coding,Source coding,Telephony,Testing,Upper bound},
language = {English},
month = may,
number = {3},
pages = {337--343},
publisher = {IEEE},
title = {{A universal algorithm for sequential data compression}},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=1055714},
volume = {23},
year = {1977}
}
@misc{,
title = {{Page Not Found | Web3D Consortium}},
url = {http://www.web3d.org/x3d/overview.html},
urldate = {2015-09-08}
}
@misc{insider2015,
title = {{THE VIRTUAL REALITY REPORT: Forecasts, market size, and the trends driving adoption}},
url = {http://www.businessinsider.com/virtual-reality-headset-sales-explode-2015-4},
urldate = {2015-06-08}
}
@misc{photosphere,
title = {{Photo Sphere XMP Metadata - Photo Sphere — Google Developers}},
url = {https://developers.google.com/photo-sphere/metadata/},
urldate = {2015-05-08},
year = {2014}
}
@misc{,
file = {:C$\backslash$:/Users/vipula/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - US7978931.enw:enw},
title = {{US7978931}}
}
@misc{,
keywords = {360 degree,gui,image stitching,panorama,panorama tools,panoramic images,photo stitching,stitcher,stitching software,windows},
title = {{Photo stitching software 360 degree Panorama image software - PTGui}},
url = {http://www.ptgui.com/}
}
@misc{owl,
title = {{OWL Web Ontology Language Guide}},
url = {http://www.w3.org/TR/owl-guide/},
urldate = {2015-09-08}
}
@misc{,
keywords = {apps-software,cameras,mobile,tech,uncategorized,virtual-reality,youtube},
title = {{YouTube's 360-degree video could mean big things for VR}},
url = {http://mashable.com/2015/03/16/youtube-adds-360-video-support/},
urldate = {2015-05-08}
}
@misc{google,
publisher = {google},
title = {{Google Photos}},
url = {https://play.google.com/store/apps/details?id=com.google.android.apps.photos\&hl=en}
}
@misc{,
title = {{- Beacon - Hill Holliday - advertising agency / marketing communications - Boston, New York}},
url = {http://www.hhcc.com/beacon/oculus-rift},
urldate = {2015-05-08}
}
@misc{samsung,
keywords = {Samsung Gear VR,live streaming virtual reality},
title = {{World-first live streaming virtual reality birth using Samsung Gear VR | SAMSUNG Australia}},
url = {http://www.samsung.com/au/news/local/world-first-live-streaming-virtual-reality-birth-using-samsung-gear-vr},
urldate = {2015-09-08}
}
@misc{,
title = {{WeMakeVR | Simply said, We Make VR.}},
url = {http://www.wemakevr.com/},
urldate = {2015-05-08}
}
@misc{adobe,
title = {{Adobe Extensible Metadata Platform (XMP)}},
url = {http://www.adobe.com/products/xmp.html},
urldate = {2015-09-08}
}
@misc{ladybug,
keywords = {ProductInterfaces},
title = {{Ladybug 360 Degree USB3 Spherical Camera Systems Point Grey USB 3.0, Gigabit Ethernet and FireWire Machine Vision Cameras}},
url = {http://www.ptgrey.com/ladybug5-360-degree-usb3-spherical-camera-systems},
urldate = {2015-09-09}
}
@misc{,
title = {{Is virtual reality the future of news? Documentaries go 360-degrees as three are launched in one day - News - Gadgets and Tech - The Independent}},
url = {http://www.independent.co.uk/life-style/gadgets-and-tech/news/is-virtual-reality-the-future-of-news-documentaries-go-360degrees-as-three-are-launched-in-one-day-9999256.html},
urldate = {2015-05-08}
}
@misc{rdf,
title = {{RDF 1.1 Semantics}},
url = {http://www.w3.org/TR/2014/REC-rdf11-mt-20140225/},
urldate = {2015-09-08}
}
@misc{,
title = {{Refs - platform/packages/apps/Camera - Git at Google}},
url = {https://android.googlesource.com/platform/packages/apps/Camera/+refs},
urldate = {2015-05-08}
}
@misc{jaunt2015,
title = {{Technology — Jaunt}},
url = {http://www.jauntvr.com/technology/},
urldate = {2015-04-30}
}
@misc{cardboard,
title = {{Google Cardboard – Google}},
url = {https://www.google.com/get/cardboard/},
urldate = {2015-06-15}
}
@misc{x3d,
title = {{What is X3D | Web3D Consortium}},
url = {http://www.web3d.org/x3d/what-x3d},
urldate = {2015-09-08}
}
@misc{,
keywords = {360 video,360 videos,create 360 videos,how to create 360 videos,stitch videos,video stitching},
title = {{Kolor | How to create 360-degree videos}},
url = {http://www.kolor.com/360-videos/},
urldate = {2015-05-08}
}
@misc{,
title = {{Virtual Video Camera - Computer Graphics Lab - TU Braunschweig}},
url = {http://graphics.tu-bs.de/projects/vvc/},
urldate = {2015-05-08}
}
@misc{,
title = {{Home | Koncept VR}},
url = {http://www.konceptvr.com/},
urldate = {2015-05-08}
}
@misc{,
publisher = {lukeyeager},
title = {{StitcHD}},
url = {https://github.com/lukeyeager/StitcHD}
}
@misc{,
title = {{Adaptive 3D Algorithm - vorpX - VR 3D-Driver for Oculus Rift}},
url = {https://www.vorpx.com/adaptive-3d-algorithm/},
urldate = {2015-05-08}
}
@misc{vrml,
title = {{Virtual Reality Modeling Language (VRML)}},
url = {http://www.acm.org/tsc/vrml.html},
urldate = {2015-09-08}
}
@misc{,
keywords = {QTVR},
title = {{QTVR}},
url = {http://www.ptgui.com/info/qtvr.html},
urldate = {2015-05-08}
}
@misc{,
title = {{Hugin - Panorama photo stitcher}},
url = {http://hugin.sourceforge.net/},
year = {2014}
}
@misc{,
title = {{Panoramic Image Projections}},
url = {http://www.cambridgeincolour.com/tutorials/image-projections.htm},
urldate = {2015-05-08}
}
@misc{vahanvr,
title = {{Live VR Video software | VideoStitch Vahana VR}},
url = {http://www.video-stitch.com/vahana-vr/},
urldate = {2015-04-30}
}
@misc{hpzvr,
keywords = {3D monitors,HP Z displays,computer monitor displays,curved displays.,interactive displays,specialty computer displays},
title = {{Specialty Z Displays | HP® Official Site}},
url = {http://www8.hp.com/us/en/campaigns/workstations/specialtyzdisplays.html},
urldate = {2015-09-08}
}
@misc{,
title = {{Mapping the sphere}},
url = {http://math.rice.edu/~polking/cartography/cart.pdf},
urldate = {2015-05-08}
}
@misc{,
keywords = {100 best places around the world,360,3D tour,RC helicopter,VR360,aerial,air,airpano.com,ball head,citiscape,city,equipment,fisheye,helicopter,high resolution quality,hundred best places,landscape,lense,nodal point,panorama,photo,photography,place,spherical panorama,technique,virtual tour},
title = {{Spherical 360 Video, Test Shooting | 360° Aerial Panorama, 3D Virtual Tours Around the World, Photos of the Most Interesting Places on the Earth}},
url = {http://www.airpano.com/Articles-AirPano.php?article=101606},
urldate = {2015-05-08}
}
